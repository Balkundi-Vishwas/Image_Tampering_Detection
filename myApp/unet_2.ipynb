{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14fmL4RcBloe"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "\n",
        "#! mkdir ~/.kaggle\n",
        "! cp \"/content/drive/MyDrive/kaggle.json\" ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ],
      "metadata": {
        "id": "WVp7JI0SFqmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfgimnFDFU9t"
      },
      "outputs": [],
      "source": [
        "#! mkdir ~/.kaggle\n",
        "#! cp kaggle.json ~/.kaggle/\n",
        "#! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWPQR1nSBMm-"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d divg07/casia-20-image-tampering-detection-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E49H7hYmBMj1"
      },
      "outputs": [],
      "source": [
        "!unzip casia-20-image-tampering-detection-dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBrJk8W5_dWy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import gridspec\n",
        "import os\n",
        "import cv2\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "import warnings\n",
        "import math\n",
        "import pickle as pk\n",
        "import datetime\n",
        "import albumentations\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from imageio import imread\n",
        "import imageio\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import layers,Model,Sequential\n",
        "from tensorflow.keras.layers import Dropout,Activation,InputLayer,LSTM,GRU,Bidirectional,TimeDistributed,Flatten,Dense,BatchNormalization,MaxPooling2D,Conv2D,Input,Concatenate,LeakyReLU\n",
        "warnings.filterwarnings('ignore')\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from tensorflow.keras.layers import concatenate, add\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XX7y1wkA8tr"
      },
      "outputs": [],
      "source": [
        "masked_dict  = {'name':[],'height':[], 'width':[], 'channels':[]}\n",
        "data_dict = {'name':[],'height':[], 'width':[], 'channels':[],'label':[]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PalF0pyeEKVm"
      },
      "outputs": [],
      "source": [
        "for image in tqdm(os.listdir('/content/CASIA2/CASIA 2 Groundtruth')):\n",
        "    if image.endswith('jpg') or image.endswith('png'):\n",
        "        img = imread('/content/CASIA2/CASIA 2 Groundtruth'+'/'+image)\n",
        "        if len(img.shape)==2:\n",
        "            height, width = img.shape\n",
        "            channels = 1\n",
        "        else:\n",
        "            height, width, channels = img.shape\n",
        "        masked_dict['name'].append(image)\n",
        "        masked_dict['height'].append(height)\n",
        "        masked_dict['width'].append(width)\n",
        "        masked_dict['channels'].append(channels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(masked_dict)"
      ],
      "metadata": {
        "id": "uPN-Am6HTyPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(masked_dict[\"height\"])"
      ],
      "metadata": {
        "id": "fdpGscxnT3ZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "km5hHC7ET3bo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nGReXIkzT3e-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFVufgBtFZA2"
      },
      "outputs": [],
      "source": [
        "for image in tqdm(os.listdir('/content/CASIA2/Tp')):\n",
        "    if image.endswith('jpg') or image.endswith('png'):\n",
        "        img = imread('/content/CASIA2/Tp'+'/'+image)\n",
        "        if len(img.shape)==2:\n",
        "            height, width = img.shape\n",
        "            channels = 1\n",
        "        else:\n",
        "            height, width, channels = img.shape\n",
        "        data_dict['name'].append(image)\n",
        "        data_dict['height'].append(height)\n",
        "        data_dict['width'].append(width)\n",
        "        data_dict['channels'].append(channels)\n",
        "        data_dict['label'].append('fake')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "90KxcFsNT2xB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLaG6fhNFYtd"
      },
      "outputs": [],
      "source": [
        "for image in tqdm(os.listdir('/content/CASIA2/Au')):\n",
        "    if image.endswith('jpg') or image.endswith('png'):\n",
        "        img = imread('/content/CASIA2/Au'+'/'+image)\n",
        "        if len(img.shape)==2:\n",
        "            height, width = img.shape\n",
        "            channels = 1\n",
        "        else:\n",
        "            height, width, channels = img.shape\n",
        "        data_dict['name'].append(image)\n",
        "        data_dict['height'].append(height)\n",
        "        data_dict['width'].append(width)\n",
        "        data_dict['channels'].append(channels)\n",
        "        data_dict['label'].append('pristine')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dict.keys()"
      ],
      "metadata": {
        "id": "wEjHwSYCUbK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "masked_dict.keys()"
      ],
      "metadata": {
        "id": "XFKsdf0_UbTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_dict['height'][0])"
      ],
      "metadata": {
        "id": "-SLx32MBUbk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aT6Xpfy9HZ5A"
      },
      "outputs": [],
      "source": [
        "data_df = pd.DataFrame.from_dict(data_dict)\n",
        "masked_df = pd.DataFrame.from_dict(masked_dict)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_df.shape"
      ],
      "metadata": {
        "id": "nhAzp83rVSK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "masked_df.shape"
      ],
      "metadata": {
        "id": "8RJcYPZQVSOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df"
      ],
      "metadata": {
        "id": "CRTJGXh3VSQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "masked_df"
      ],
      "metadata": {
        "id": "j2sME6y4Vzki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5r7mrxKIcIa"
      },
      "outputs": [],
      "source": [
        "masked_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_j5c_9QcIcFo"
      },
      "outputs": [],
      "source": [
        "data_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5y8Nc0DIiE7"
      },
      "outputs": [],
      "source": [
        "data_df.duplicated().any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtAaDCyxIodG"
      },
      "outputs": [],
      "source": [
        "masked_df.duplicated().any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34zwnIEpIswq"
      },
      "outputs": [],
      "source": [
        "lables= data_df['label'].value_counts()\n",
        "ax=lables.plot.bar(width=.8,title='Labels in Train Data', rot=0)\n",
        "for i, v in lables.reset_index().iterrows():\n",
        "    ax.text(i, v.label, v.label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9N2RMMC_Ist8"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1,2,figsize=(15,5))\n",
        "ax[0].set_title('PDF of FAKE Image heights')\n",
        "sns.distplot(data_df[data_df['label']=='fake'].height,ax=ax[0])\n",
        "ax[0].set_xlabel(\"Image height in pixels\")\n",
        "#sns.distplot(data_df[data_df['label']=='pristine'].height)\n",
        "ax[0].set_xlabel(\"Image height in pixels\")\n",
        "sns.distplot(data_df[data_df['label']=='pristine'].height,ax=ax[1])\n",
        "#sns.distplot(data_df[data_df['label']=='pristine'].height)\n",
        "ax[1].set_xlabel(\"Image height in pixels\")\n",
        "ax[1].set_title('PDF of PRISTINE Image heights')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_G2gRbhJD1J"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1,2,figsize=(15,5))\n",
        "ax[0].set_title('PDF of FAKE Image widths')\n",
        "sns.distplot(data_df[data_df['label']=='fake'].width,ax=ax[0])\n",
        "ax[0].set_xlabel(\"Image widths in pixels\")\n",
        "ax[0].set_xlabel(\"Image widths in pixels\")\n",
        "sns.distplot(data_df[data_df['label']=='pristine'].width,ax=ax[1])\n",
        "ax[1].set_xlabel(\"Image widths in pixels\")\n",
        "ax[1].set_title('PDF of PRISTINE Image widths')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YI_oFK_cJDyR"
      },
      "outputs": [],
      "source": [
        "lables= data_df['channels'].value_counts()\n",
        "ax=lables.plot.bar(width=.8,title='Channels in Images', rot=0)\n",
        "for i, v in lables.reset_index().iterrows():\n",
        "    ax.text(i, v.channels, v.channels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oS8AZiqoJDvn"
      },
      "outputs": [],
      "source": [
        "lables= masked_df['channels'].value_counts()\n",
        "ax=lables.plot.bar(width=.8,title='Channels in Mask images', rot=0)\n",
        "for i, v in lables.reset_index().iterrows():\n",
        "    ax.text(i, v.channels, v.channels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBhYoz0WPHvM"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "image = imread('/content/CASIA2/Au'+'/'+(data_df[data_df.label=='pristine']['name']).iloc[120])\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "#     # Apply Canny edge detection\n",
        "edges = cv2.Canny(gray,100,200)\n",
        "plt.imshow(image)\n",
        "plt.title('A Sample from PRISTINE images')\n",
        "plt.show()\n",
        "plt.imshow(edges)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tl8AOTHQpqOH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQLCLTK2pqLT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RKgdt4_PHsM"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1,2,figsize=(15,15))\n",
        "index = 15\n",
        "image = imread('/content/CASIA2/Tp'+'/'+(data_df[data_df.label=='fake']['name']).iloc[index])\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "mask_image = imread('/content/CASIA2/CASIA 2 Groundtruth'+'/'+(data_df[data_df.label=='fake']['name']).iloc[index].split('.')[0]+'_gt.png')\n",
        "mask_image = cv2.cvtColor(mask_image, cv2.COLOR_BGR2RGB)\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "#     # Perform histogram equalization to improve contrast\n",
        "equalized = cv2.equalizeHist(blurred)\n",
        "edges = cv2.Canny(equalized,200,500)\n",
        "\n",
        "ax[0].imshow(image)\n",
        "ax[1].imshow(mask_image,cmap='gray')\n",
        "ax[0].set_title('A Sample from FAKE images')\n",
        "ax[1].set_title('Corresponding MASK for this FAKE image')\n",
        "plt.imshow(edges)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhAfApU_tWSY"
      },
      "outputs": [],
      "source": [
        "plt.imshow(edges)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9w5IyhzT_Le"
      },
      "outputs": [],
      "source": [
        "index = 300\n",
        "fig, ax = plt.subplots(1,2,figsize=(15,15))\n",
        "image = imread('/content/CASIA2/Tp'+'/'+(data_df[data_df.label=='fake']['name']).iloc[index])\n",
        "#image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "mask_image = imread('/content/CASIA2/CASIA 2 Groundtruth'+'/'+(data_df[data_df.label=='fake']['name']).iloc[index].split('.')[0]+'_gt.png')\n",
        "#mask_image = cv2.cvtColor(mask_image, cv2.COLOR_BGR2RGB)\n",
        "ax[0].imshow(image)\n",
        "ax[1].imshow(mask_image,cmap='gray')\n",
        "ax[0].set_title('A Sample from FAKE images')\n",
        "ax[1].set_title('Corresponding MASK for this FAKE image')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcLMle0HV0fK"
      },
      "outputs": [],
      "source": [
        "print(\"Total FAKE images in the data: {}\".format(len(set(list(data_df[data_df.label=='fake']['name'])))))\n",
        "print(\"Total availble Masks for the data: {}\".format(len(set(list(masked_df['name'])))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYK9fc_EV_7p"
      },
      "outputs": [],
      "source": [
        "print(\"Total pristine images in the data: {}\".format(len(set(list(data_df[data_df.label=='pristine']['name'])))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbV_RNMnWCrQ"
      },
      "outputs": [],
      "source": [
        "fake_names = list(set([i.split('.')[0] for i in list(masked_df['name'])]) & set([i.replace('.jpg','_gt.png').split('.')[0] for i in list(data_df[data_df.label=='fake']['name'])]))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(fake_names)"
      ],
      "metadata": {
        "id": "LRZdRwDXWWm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjGsKohcRSpB"
      },
      "outputs": [],
      "source": [
        "fake_names1 = list(set([i.split('.')[0] for i in list(masked_df['name'])]) & set([i.replace('.jpg','.png').split('.')[0] for i in list(data_df[data_df.label=='fake']['name'])]))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fake_names1"
      ],
      "metadata": {
        "id": "oNw3AMiUWpzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLgbhS7t1R48"
      },
      "outputs": [],
      "source": [
        "data_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9W87Gi0c0_Z1"
      },
      "outputs": [],
      "source": [
        "print(fake_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlAPs6NMW-el"
      },
      "outputs": [],
      "source": [
        "print(\"Total intersection of Masks and FAKE images in the data: {}\".format(len(fake_names)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEepIxDO0bMX"
      },
      "outputs": [],
      "source": [
        "delete_these = []\n",
        "for image in fake_names:\n",
        "    mask_img = cv2.imread('/content/CASIA2/CASIA 2 Groundtruth'+'/'+image+'.png')\n",
        "    fake_img = cv2.imread('/content/CASIA2/Tp'+'/'+image.replace('_gt','')+'.jpg')\n",
        "    if mask_img.shape[:2]!= fake_img.shape[:2]:\n",
        "        delete_these.append(image)\n",
        "#delete_these"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CA6t7IEwW_1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1UB5UZRJW_pJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(delete_these)"
      ],
      "metadata": {
        "id": "yjUt3kSiW16k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NXItcmB0a8d"
      },
      "outputs": [],
      "source": [
        "fake_names=list(set(fake_names)-set(delete_these))\n",
        "print(\"Total valid masks are :{}\".format(len(fake_names)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YH2Z22jQXSRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRwsOCVqQ7KB"
      },
      "outputs": [],
      "source": [
        "fake_names1=[sub.replace('_gt', '') for sub in fake_names]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWBQ9U8g0a1i"
      },
      "outputs": [],
      "source": [
        "dest_path='/content/binary_images1/'\n",
        "# os.makedirs(dest_path)\n",
        "bin_masks =[]\n",
        "for mask in tqdm(fake_names):\n",
        "    mask_img = cv2.imread('/content/CASIA2/CASIA 2 Groundtruth'+'/'+mask+'.png')[:,:,:1]\n",
        "    #mask_img= cv2.cvtColor(mask_img, cv2.COLOR_BGR2GRAY)\n",
        "    blur = cv2.GaussianBlur(mask_img,(5,5),0) #Adding gaussian blur\n",
        "    ret,bin_mask = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU) #modifing the values to either 0 or 255\n",
        "    cv2.imwrite(dest_path+mask+'binary.png',bin_mask)\n",
        "    bin_masks.append(bin_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eR8C4xDS5xif"
      },
      "outputs": [],
      "source": [
        "# index = 104\n",
        "# fig, ax = plt.subplots(1,3,figsize=(20,20))\n",
        "# image = imread('/content/CASIA2/Tp'+'/'+(data_df[data_df.label=='fake']['name']).iloc[index])\n",
        "# #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "# mask_image = imread('/content/CASIA2/CASIA 2 Groundtruth'+'/'+(data_df[data_df.label=='fake']['name']).iloc[index].split('.')[0]+'_gt.png')\n",
        "# #mask_image = cv2.cvtColor(mask_image, cv2.COLOR_BGR2RGB)\n",
        "# bin_mask = imread('/content/binary_images1/'+(data_df[data_df.label=='fake']['name']).iloc[index].split('.')[0]+'_gtbinary.png')\n",
        "# #bin_mask = cv2.cvtColor(bin_mask, cv2.COLOR_BGR2GRAY)\n",
        "# ax[0].imshow(image)\n",
        "# ax[1].imshow(mask_image,cmap='gray')\n",
        "# ax[2].imshow(bin_mask,cmap='gray')\n",
        "# ax[0].set_title('A Sample from FAKE images')\n",
        "# ax[1].set_title('Corresponding MASK for this FAKE image')\n",
        "# ax[2].set_title('BINARY-MASK for this FAKE image')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3TmCFg86Cn_"
      },
      "outputs": [],
      "source": [
        "# data_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBK0iG9U6FBA"
      },
      "outputs": [],
      "source": [
        "fake_names_df = pd.DataFrame([i+'.jpg' for i in fake_names1],columns=['name'])\n",
        "data_df_real = data_df[data_df.label == 'pristine']\n",
        "data_df_fake = data_df[data_df.label == 'fake']\n",
        "data_df_fake = data_df_fake.join(fake_names_df.set_index('name'), on='name',how='right')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bh6p7xcBBPzJ"
      },
      "outputs": [],
      "source": [
        "data_df_final = pd.concat([data_df_real, data_df_fake], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5JAyMPxBPnD"
      },
      "outputs": [],
      "source": [
        "data_df_fake.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JRF9cx2MX1Bu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PLwNgk0TZqC"
      },
      "outputs": [],
      "source": [
        "data_df_real.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYyHQRD-TfgL"
      },
      "outputs": [],
      "source": [
        "data_df_final.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGHyb0ABEWI-"
      },
      "outputs": [],
      "source": [
        "data_df_final.to_csv('data_df_final.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVlICbuCEWDr"
      },
      "outputs": [],
      "source": [
        "lables= data_df_final['label'].value_counts()\n",
        "ax=lables.plot.bar(width=.8,title='Labels in Data after cleaning', rot=0)\n",
        "for i, v in lables.reset_index().iterrows():\n",
        "    ax.text(i, v.label, v.label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYYBZ-BZEWBK"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data_df_final[['channels', 'height', 'name', 'width','label']],\n",
        "                                                    data_df_final['label'],\n",
        "                                                    test_size=0.2,\n",
        "                                                    stratify=data_df_final['label'],\n",
        "                                                    random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnvmJ7ugUVmn"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train[['channels', 'height', 'name', 'width','label']],\n",
        "                                                  y_train, test_size=0.2, stratify=y_train,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQZkGAk2UVjt"
      },
      "outputs": [],
      "source": [
        "print(\"........Data splits before the Agumentation...........\")\n",
        "print(\"Images in Train data before sampling: {} \".format(X_train.shape[0]))\n",
        "print(\"Images in Test data  before sampling: {} \".format(X_test.shape[0]))\n",
        "print(\"Images in Validation data before sampling: {} \".format(X_val.shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LKJomHtUj5D"
      },
      "outputs": [],
      "source": [
        "X_train.to_csv('X_train.csv',index=False)\n",
        "X_test.to_csv('X_test.csv',index=False)\n",
        "X_val.to_csv('X_val.csv',index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qR34lPFDUVgx"
      },
      "outputs": [],
      "source": [
        "X_train= pd.read_csv('X_train.csv')\n",
        "X_test= pd.read_csv('X_test.csv')\n",
        "X_val= pd.read_csv('X_val.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWb1S7yzUpnB"
      },
      "outputs": [],
      "source": [
        "from albumentations import (\n",
        "PadIfNeeded,\n",
        "HorizontalFlip,\n",
        "VerticalFlip,\n",
        "Transpose,\n",
        "HueSaturationValue,\n",
        "ElasticTransform,\n",
        "GridDistortion,\n",
        "OpticalDistortion,\n",
        "RandomBrightnessContrast,\n",
        "RandomGamma,Resize\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOqes4FTUpkU"
      },
      "outputs": [],
      "source": [
        "def agument(aug,image,mask):\n",
        "    \"\"\"This function will apply the type of augmentation on both image and mask\n",
        "    returns augmented image and its augmented mask\n",
        "    \"\"\"\n",
        "    augmented = aug(image=image, mask=mask)\n",
        "    return augmented['image'],augmented['mask']\n",
        "\n",
        "\n",
        "# All these below functions defines the different agumentations types.\n",
        "\n",
        "def resize(image,mask): #While agumenting the data we are converting all images into the size of (512,512)\n",
        "    aug = Resize(height=512,width=512,p=1)\n",
        "    return agument(aug,image,mask)\n",
        "\n",
        "def horizontalFlip(image,mask):\n",
        "    aug = HorizontalFlip(p=1)\n",
        "    return agument(aug,image,mask)\n",
        "\n",
        "def verticalFlip(image,mask):\n",
        "    aug = VerticalFlip(p=1)\n",
        "    return agument(aug,image,mask)\n",
        "\n",
        "def transpose(image,mask):\n",
        "    aug = Transpose(p=1)\n",
        "    return agument(aug,image,mask)\n",
        "\n",
        "def hueSaturationValue(image,mask):\n",
        "    aug = HueSaturationValue(p=1,hue_shift_limit=100, sat_shift_limit=100, val_shift_limit=50)\n",
        "    return agument(aug,image,mask)\n",
        "\n",
        "def elasticTransform(image,mask):\n",
        "    aug = ElasticTransform(p=1)\n",
        "    return agument(aug,image,mask)\n",
        "\n",
        "def opticalDistortion(image,mask):\n",
        "    aug = OpticalDistortion(p=1, distort_limit=3, shift_limit=0.4)\n",
        "    return agument(aug,image,mask)\n",
        "\n",
        "def randomBrightnessContrast(image,mask):\n",
        "    aug =RandomBrightnessContrast(p=1,brightness_limit=0.5, contrast_limit=0.4)\n",
        "    return agument(aug,image,mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iaqORHBXVQsA"
      },
      "outputs": [],
      "source": [
        "# def resize(image,mask): #While agumenting the data we are converting all images into the size of (512,512)\n",
        "#     aug = Resize(height=512,width=512,p=1)\n",
        "#     return agument(aug,image,mask)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KINN-yVPUphP"
      },
      "outputs": [],
      "source": [
        "# index=31\n",
        "# fig, ax = plt.subplots(9,2,figsize=(10,40))\n",
        "# image_raw= imread('/content/CASIA2/Tp/'+X_train[X_train['label']=='fake']['name'].iloc[index])\n",
        "# mask_raw = imread('/content/CASIA2/CASIA 2 Groundtruth/'+X_train[X_train['label']=='fake']['name'].iloc[index].split('.')[0]+'_gt.png')\n",
        "\n",
        "# image,mask= resize(image=image_raw,mask=mask_raw)\n",
        "# image_h,mask_h= horizontalFlip(image=image,mask=mask)\n",
        "# image_v,mask_v= verticalFlip(image=image,mask=mask)\n",
        "# image_t,mask_t= transpose(image=image,mask=mask)\n",
        "# image_hue,mask_hue= hueSaturationValue(image=image,mask=mask)\n",
        "# image_elt,mask_elt= elasticTransform(image=image,mask=mask)\n",
        "# image_opt,mask_opt= opticalDistortion(image=image,mask=mask)\n",
        "# image_rbc,mask_rbc= randomBrightnessContrast(image=image,mask=mask)\n",
        "\n",
        "# ax[0][0].imshow(image_raw)\n",
        "# ax[0][1].imshow(mask_raw,cmap='gray')\n",
        "# ax[0][0].set_title('Raw FAKE image')\n",
        "# ax[0][1].set_title('corresponding MASK for this FAKE image')\n",
        "# ax[1][0].imshow(image)\n",
        "# ax[1][1].imshow(mask,cmap='gray')\n",
        "# ax[1][0].set_title('A resized FAKE image')\n",
        "# ax[1][1].set_title('resized MASK for this FAKE image')\n",
        "# ax[2][0].imshow(image_h)\n",
        "# ax[2][1].imshow(mask_h,cmap='gray')\n",
        "# ax[2][0].set_title('horizontally fliped image')\n",
        "# ax[2][1].set_title('horizontally fliped mask')\n",
        "# ax[3][0].imshow(image_v)\n",
        "# ax[3][1].imshow(mask_v,cmap='gray')\n",
        "# ax[3][0].set_title('vertically fliped image')\n",
        "# ax[3][1].set_title('vertically fliped mask')\n",
        "# ax[4][0].imshow(image_t)\n",
        "# ax[4][1].imshow(mask_t,cmap='gray')\n",
        "# ax[4][0].set_title('transposed image')\n",
        "# ax[4][1].set_title('transposed mask')\n",
        "# ax[5][0].imshow(image_hue)\n",
        "# ax[5][1].imshow(mask_hue,cmap='gray')\n",
        "# ax[5][0].set_title('hue shifted image')\n",
        "# ax[5][1].set_title('hue shifted mask')\n",
        "# ax[6][0].imshow(image_elt)\n",
        "# ax[6][1].imshow(mask_elt,cmap='gray')\n",
        "# ax[6][0].set_title('elastic_transformed image')\n",
        "# ax[6][1].set_title('elastic_transformed mask')\n",
        "# ax[7][0].imshow(image_opt)\n",
        "# ax[7][1].imshow(mask_opt,cmap='gray')\n",
        "# ax[7][0].set_title('optical_distorted image')\n",
        "# ax[7][1].set_title('optical_distorted mask')\n",
        "# ax[8][0].imshow(image_rbc)\n",
        "# ax[8][1].imshow(mask_rbc,cmap='gray')\n",
        "# ax[8][0].set_title('Brightness modified image')\n",
        "# ax[8][1].set_title('Brightness modified mask')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQE8Sia5Vpoa"
      },
      "outputs": [],
      "source": [
        "train_path_fk = 'data_agumented/train/fake/'\n",
        "test_path_fk = 'data_agumented/test/fake/'\n",
        "val_path_fk = 'data_agumented/val/fake/'\n",
        "os.makedirs(train_path_fk)\n",
        "os.makedirs(test_path_fk)\n",
        "os.makedirs(val_path_fk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUSQ1WqJUz1B"
      },
      "outputs": [],
      "source": [
        "def DataAgument(split_type,Type):\n",
        "    \"\"\"Function will accept the data in \"split_type\" and name of the split in \"Type\"\n",
        "     From the data, it will take only FAKE images and its masks.\n",
        "    for each fake image:\n",
        "        1. It will resizes the image and its mask\n",
        "        2. And apply 6 kinds of agumentations\n",
        "        3. Finally saves the agumented images and masks\n",
        "\n",
        "    \"\"\"\n",
        "    for name in tqdm(split_type[split_type['label']=='fake']['name']):\n",
        "        name_path ='/content/CASIA2/Tp/'+str(name)\n",
        "        image_raw= imread(name_path)\n",
        "        mask_raw = imread('/content/CASIA2/CASIA 2 Groundtruth/'+name.split('.')[0]+'_gt.png')\n",
        "        image_0,mask_0= resize(image=image_raw,mask=mask_raw)\n",
        "        # image_1,mask_1= horizontalFlip(image=image_0,mask=mask_0)\n",
        "        # image_2,mask_2= verticalFlip(image=image_0,mask=mask_0)\n",
        "        # image_3,mask_3= transpose(image=image_0,mask=mask_0)\n",
        "        # image_4,mask_4= hueSaturationValue(image=image_0,mask=mask_0)\n",
        "        # image_5,mask_5= elasticTransform(image=image_0,mask=mask_0)\n",
        "        # image_6,mask_6= opticalDistortion(image=image_0,mask=mask_0)\n",
        "        # image_7,mask_7= randomBrightnessContrast(image=image_0,mask=mask_0)\n",
        "        cv2.imwrite('data_agumented/'+Type+'/fake/'+name.split('.')[0]+'_'+str(0)+'.png',image_0)\n",
        "        cv2.imwrite('data_agumented/'+Type+'/fake/'+name.split('.')[0]+'_'+str(0)+'.mask.png',mask_0)\n",
        "        # cv2.imwrite('data_agumented/'+Type+'/fake/'+name.split('.')[0]+'_'+str(1)+'.png',image_1)\n",
        "        # cv2.imwrite('data_agumented/'+Type+'/fake/'+name.split('.')[0]+'_'+str(1)+'.mask.png',mask_1)\n",
        "        # cv2.imwrite('data_agumented/'+Type+'/fake/'+name.split('.')[0]+'_'+str(2)+'.png',image_2)\n",
        "        # cv2.imwrite('data_agumented/'+Type+'/fake/'+name.split('.')[0]+'_'+str(2)+'.mask.png',mask_2)\n",
        "        # cv2.imwrite('data_agumented/'+Type+'/fake/'+name.split('.')[0]+'_'+str(3)+'.png',image_3)\n",
        "        # cv2.imwrite('data_agumented/'+Type+'/fake/'+name.split('.')[0]+'_'+str(3)+'.mask.png',mask_3)\n",
        "        # cv2.imwrite('data_agumented/'+Type+'/fake/'+name.split('.')[0]+'_'+str(4)+'.png',image_4)\n",
        "        # cv2.imwrite('data_agumented/'+Type+'/fake/'+name.split('.')[0]+'_'+str(4)+'.mask.png',mask_4)\n",
        "        # cv2.imwrite('data_agumented/'+Type+'/fake/'+name.split('.')[0]+'_'+str(5)+'.png',image_5)\n",
        "        # cv2.imwrite('data_agumented/'+Type+'/fake/'+name.split('.')[0]+'_'+str(5)+'.mask.png',mask_5)\n",
        "        # cv2.imwrite('data_agumented/'+Type+'/fake/'+name.split('.')[0]+'_'+str(6)+'.png',image_6)\n",
        "        # cv2.imwrite('data_agumented/'+Type+'/fake/'+name.split('.')[0]+'_'+str(6)+'.mask.png',mask_6)\n",
        "        # cv2.imwrite('data_agumented/'+Type+'/fake/'+name.split('.')[0]+'_'+str(7)+'.png',image_7)\n",
        "        # cv2.imwrite('data_agumented/'+Type+'/fake/'+name.split('.')[0]+'_'+str(7)+'.mask.png',mask_7)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbhadvmVUzyj"
      },
      "outputs": [],
      "source": [
        "DataAgument(split_type=X_train,Type=\"train\")\n",
        "DataAgument(split_type=X_test,Type=\"test\")\n",
        "DataAgument(split_type=X_val,Type=\"val\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5EMnZh7QUzvo"
      },
      "outputs": [],
      "source": [
        "print(\"Total agumented FAKE images from TRIAN Split: {}\".format(len(os.listdir(train_path_fk))/2))\n",
        "print(\"Total agumented FAKE images from TEST Split: {}\".format(len(os.listdir(test_path_fk))/2))\n",
        "print(\"Total agumented FAKE images from VALIDATION Split: {}\".format(len(os.listdir(val_path_fk))/2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "721Yr_A62pW_"
      },
      "outputs": [],
      "source": [
        "train_path_pr = 'data_agumented/train/pristine/'\n",
        "test_path_pr = 'data_agumented/test/pristine/'\n",
        "val_path_pr = 'data_agumented/val/pristine/'\n",
        "os.makedirs(train_path_pr)\n",
        "os.makedirs(test_path_pr)\n",
        "os.makedirs(val_path_pr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fBklCNx2ueu"
      },
      "outputs": [],
      "source": [
        "cv2.imwrite(\"default.mask.png\",np.zeros((512,512))+255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSamujYD20vB"
      },
      "outputs": [],
      "source": [
        "def DataAgument_pristine(split_type,Type):\n",
        "    for name in tqdm(split_type[split_type['label']=='pristine']['name']):\n",
        "        name_path = '/content/CASIA2/Au/'+str(name)\n",
        "        image_raw= imread(name_path)\n",
        "        mask_raw= imread('default.mask.png')\n",
        "        image_0,mask_0= resize(image=image_raw,mask=mask_raw)\n",
        "        # image_1,mask_1= verticalFlip(image=image_0,mask=mask_raw)\n",
        "        # #image_2,mask_2= hueSaturationValue(image=image_0,mask=mask_raw)\n",
        "        # image_2,mask_2= opticalDistortion(image=image_0,mask=mask_raw)\n",
        "        cv2.imwrite('data_agumented/'+Type+'/pristine/'+name.split('.')[0]+'_'+str(0)+'.png',image_0)\n",
        "        # cv2.imwrite('data_agumented/'+Type+'/pristine/'+name.split('.')[0]+'_'+str(1)+'.png',image_1)\n",
        "        # #cv2.imwrite('data_agumented/'+Type+'/pristine/'+name.split('.')[0]+'_'+str(2)+'.png',image_2)\n",
        "        # cv2.imwrite('data_agumented/'+Type+'/pristine/'+name.split('.')[0]+'_'+str(3)+'.png',image_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fy-1Ij_56_4"
      },
      "outputs": [],
      "source": [
        "DataAgument_pristine(split_type=X_train,Type=\"train\")\n",
        "DataAgument_pristine(split_type=X_test,Type=\"test\")\n",
        "DataAgument_pristine(split_type=X_val,Type=\"val\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJcbKGIe7352"
      },
      "outputs": [],
      "source": [
        "print(\"Total agumented FAKE images from TRIAN Split: {}\".format(len(os.listdir(train_path_fk))/2))\n",
        "print(\"Total agumented FAKE images from TEST Split: {}\".format(len(os.listdir(test_path_fk))/2))\n",
        "print(\"Total agumented FAKE images from VALIDATION Split: {}\".format(len(os.listdir(val_path_fk))/2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWVY-aea99Fj"
      },
      "outputs": [],
      "source": [
        "print(\"Total agumented Pristine images from TRIAN Split: {}\".format(len(os.listdir(train_path_pr))))\n",
        "print(\"Total agumented Pristine images from TEST Split: {}\".format(len(os.listdir(test_path_pr))))\n",
        "print(\"Total agumented Pristine images from VALIDATION Split: {}\".format(len(os.listdir(val_path_pr))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6FXv4TD-AVs"
      },
      "outputs": [],
      "source": [
        "train_path_fk = 'data_agumented/train/fake/'\n",
        "test_path_fk = 'data_agumented/test/fake/'\n",
        "val_path_fk = 'data_agumented/val/fake/'\n",
        "train_path_pr = 'data_agumented/train/pristine/'\n",
        "test_path_pr = 'data_agumented/test/pristine/'\n",
        "val_path_pr = 'data_agumented/val/pristine/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S35TMJey-DOp"
      },
      "outputs": [],
      "source": [
        "train_data = pd.DataFrame()\n",
        "X_label = []\n",
        "y_label = []\n",
        "for i in (list({i.split('.')[0] for i in os.listdir(train_path_fk)})):\n",
        "    X_label.append(train_path_fk+i+'.png')\n",
        "    y_label.append(train_path_fk+i+'.mask.png')\n",
        "for i in (list({i.split('.')[0] for i in os.listdir(train_path_pr)})):\n",
        "    X_label.append(train_path_pr+i+'.png')\n",
        "    y_label.append('default.mask.png')\n",
        "\n",
        "train_data['X']  =  X_label\n",
        "train_data['y']  =  y_label\n",
        "train_data = shuffle(train_data)\n",
        "train_data.reset_index(inplace=True, drop=True)\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IV7vpnJl-GTQ"
      },
      "outputs": [],
      "source": [
        "print(train_data.shape)\n",
        "# print(test_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkIIal_7-JD1"
      },
      "outputs": [],
      "source": [
        "test_data = pd.DataFrame()\n",
        "X_label = []\n",
        "y_label = []\n",
        "for i in (list({i.split('.')[0] for i in os.listdir(test_path_fk)})):\n",
        "    X_label.append(test_path_fk+i+'.png')\n",
        "    y_label.append(test_path_fk+i+'.mask.png')\n",
        "for i in (list({i.split('.')[0] for i in os.listdir(test_path_pr)})):\n",
        "    X_label.append(test_path_pr+i+'.png')\n",
        "    y_label.append('default.mask.png')\n",
        "\n",
        "test_data['X']  =  X_label\n",
        "test_data['y']  =  y_label\n",
        "test_data = shuffle(test_data)\n",
        "test_data.reset_index(inplace=True, drop=True)\n",
        "test_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEWOgMNA-LJ2"
      },
      "outputs": [],
      "source": [
        "test_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HznG3AYb-Nb0"
      },
      "outputs": [],
      "source": [
        "val_data = pd.DataFrame()\n",
        "X_label = []\n",
        "y_label = []\n",
        "for i in (list({i.split('.')[0] for i in os.listdir(val_path_fk)})):\n",
        "    X_label.append(val_path_fk+i+'.png')\n",
        "    y_label.append(val_path_fk+i+'.mask.png')\n",
        "for i in (list({i.split('.')[0] for i in os.listdir(val_path_pr)})):\n",
        "    X_label.append(val_path_pr+i+'.png')\n",
        "    y_label.append('default.mask.png')\n",
        "\n",
        "val_data['X']  =  X_label\n",
        "val_data['y']  =  y_label\n",
        "val_data = shuffle(val_data)\n",
        "val_data.reset_index(inplace=True, drop=True)\n",
        "val_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57-0Dxtjod6A"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nD9KKJbR-Sao"
      },
      "outputs": [],
      "source": [
        "def data_gen(data):\n",
        "    while True:\n",
        "        for start in range(0, data.shape[0], batch_size):\n",
        "            x_batch = []\n",
        "            y_batch = []\n",
        "            end = min(start + batch_size, data.shape[0])\n",
        "            x_data_batch = data.iloc[start:end]\n",
        "\n",
        "            for index,row in x_data_batch.iterrows():\n",
        "                image = load_img(row['X'])\n",
        "                image = img_to_array(image)\n",
        "                mask = imread(row['y'])\n",
        "                mask= img_to_array(mask,dtype=np.uint8)\n",
        "                x_batch.append(image)\n",
        "                y_batch.append(mask)\n",
        "\n",
        "            x_batch = np.array(x_batch).reshape(-1, 512, 512, 3)/255\n",
        "            # temp= np.array(y_batch[0])\n",
        "            # #print(temp)\n",
        "            # print(temp.shape)\n",
        "            # temp.shape = (512,512)\n",
        "            # print(temp.shape)\n",
        "            # print(temp)\n",
        "            temp_arr =[]\n",
        "            #print(len(y_batch))\n",
        "            #y_batch = np.array(y_batch)/255\n",
        "            # for b in y_batch:\n",
        "            #   print(b)\n",
        "            #   b.shape = (512,512)\n",
        "            #   temp_arr.append(b)\n",
        "            # temp_arr = np.array(temp_arr)/255\n",
        "            for b in y_batch:\n",
        "              temp = b[:, :, 0]\n",
        "              temp_arr.append(temp)\n",
        "            temp_arr = np.array(temp_arr)/255\n",
        "\n",
        "            yield x_batch, temp_arr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16"
      ],
      "metadata": {
        "id": "fsiNf3Eg0GJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylKEjNMZoP98"
      },
      "outputs": [],
      "source": [
        "listed = list(data_gen(train_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4GePhVn-Yga"
      },
      "outputs": [],
      "source": [
        "# #Ref : https://www.depends-on-the-definition.com/unet-keras-segmenting-images/\n",
        "\n",
        "# def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):\n",
        "#     # first layer\n",
        "#     x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
        "#                padding=\"same\")(input_tensor)\n",
        "#     if batchnorm:\n",
        "#         x = BatchNormalization()(x)\n",
        "#     x = Activation(\"relu\")(x)\n",
        "#     # second layer\n",
        "#     x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
        "#                padding=\"same\")(x)\n",
        "#     if batchnorm:\n",
        "#         x = BatchNormalization()(x)\n",
        "#     x = Activation(\"relu\")(x)\n",
        "#     return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHDVufSv-bOW"
      },
      "outputs": [],
      "source": [
        "# def get_unet(input_img, n_filters=16, dropout=0.5, batchnorm=True):\n",
        "#     # contracting path\n",
        "#     c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
        "#     p1 = MaxPooling2D((2, 2)) (c1)\n",
        "#     p1 = Dropout(dropout*0.5)(p1)\n",
        "\n",
        "#     c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
        "#     p2 = MaxPooling2D((2, 2)) (c2)\n",
        "#     p2 = Dropout(dropout)(p2)\n",
        "\n",
        "#     c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
        "#     p3 = MaxPooling2D((2, 2)) (c3)\n",
        "#     p3 = Dropout(dropout)(p3)\n",
        "\n",
        "#     c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
        "#     p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
        "#     p4 = Dropout(dropout)(p4)\n",
        "\n",
        "#     c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)\n",
        "#     # expansive path\n",
        "#     u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)\n",
        "#     u6 = concatenate([u6, c4])\n",
        "#     u6 = Dropout(dropout)(u6)\n",
        "#     c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
        "\n",
        "#     u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)\n",
        "#     u7 = concatenate([u7, c3])\n",
        "#     u7 = Dropout(dropout)(u7)\n",
        "#     c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
        "\n",
        "#     u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)\n",
        "#     u8 = concatenate([u8, c2])\n",
        "#     u8 = Dropout(dropout)(u8)\n",
        "#     c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
        "\n",
        "#     u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)\n",
        "#     u9 = concatenate([u9, c1], axis=3)\n",
        "#     u9 = Dropout(dropout)(u9)\n",
        "#     c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
        "\n",
        "#     outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
        "#     model = Model(inputs=[input_img], outputs=[outputs])\n",
        "#     return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04cfFWz9inZ4"
      },
      "outputs": [],
      "source": [
        "def train(batch_norm=False):\n",
        "    model=Sequential()\n",
        "    model.add(Conv2D(filters=64,\n",
        "              kernel_size=(3, 3),\n",
        "              padding='same',\n",
        "              activation='relu',\n",
        "              input_shape=(224,224,3),\n",
        "              name='conv1_1'))\n",
        "    model.add(Conv2D(filters=64,\n",
        "              kernel_size=(3, 3),\n",
        "                  padding='same',\n",
        "              activation='relu',\n",
        "              name='conv1_2'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),\n",
        "                   strides=(2,2),\n",
        "                   name='max_pooling2d_1'))\n",
        "    model.add(Conv2D(filters=128,\n",
        "              kernel_size=(3, 3),\n",
        "              padding='same',\n",
        "              activation='relu',\n",
        "              name='conv2_1'))\n",
        "    model.add(Conv2D(filters=128,\n",
        "              kernel_size=(3, 3),\n",
        "                  padding='same',\n",
        "              activation='relu',\n",
        "              name='conv2_2'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),\n",
        "                 strides=(2,2),\n",
        "                 name='max_pooling2d_2'))\n",
        "    model.add(Conv2D(filters=256,\n",
        "              kernel_size=(3, 3),\n",
        "              padding='same',\n",
        "              activation='relu',\n",
        "              input_shape=(224,224,3),\n",
        "              name='conv3_1'))\n",
        "    model.add(Conv2D(filters=256,\n",
        "              kernel_size=(3, 3),\n",
        "                  padding='same',\n",
        "              activation='relu',\n",
        "              name='conv3_2'))\n",
        "    model.add(Conv2D(filters=256,\n",
        "              kernel_size=(3, 3),\n",
        "                  padding='same',\n",
        "              activation='relu',\n",
        "              name='conv3_3'))\n",
        "\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),\n",
        "                   strides=(2,2),\n",
        "                   name='max_pooling2d_3'))\n",
        "    model.add(Conv2D(filters=512,\n",
        "              kernel_size=(3, 3),\n",
        "              padding='same',\n",
        "              activation='relu',\n",
        "              input_shape=(224,224,3),\n",
        "              name='conv4_1'))\n",
        "    model.add(Conv2D(filters=512,\n",
        "              kernel_size=(3, 3),\n",
        "                  padding='same',\n",
        "              activation='relu',\n",
        "              name='conv4_2'))\n",
        "    model.add(Conv2D(filters=512,\n",
        "              kernel_size=(3, 3),\n",
        "                  padding='same',\n",
        "              activation='relu',\n",
        "              name='conv4_3'))\n",
        "\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),\n",
        "                   strides=(2,2),\n",
        "                   name='max_pooling2d_4'))\n",
        "    model.add(Conv2D(filters=512,\n",
        "              kernel_size=(3, 3),\n",
        "              padding='same',\n",
        "              activation='relu',\n",
        "              input_shape=(224,224,3),\n",
        "              name='conv5_1'))\n",
        "    model.add(Conv2D(filters=512,\n",
        "                  kernel_size=(3, 3),\n",
        "                  padding='same',\n",
        "              activation='relu',\n",
        "              name='conv5_2'))\n",
        "    model.add(Conv2D(filters=512,\n",
        "             kernel_size=(3, 3),\n",
        "                 padding='same',\n",
        "             activation='relu',\n",
        "             name='conv5_3'))\n",
        "\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),\n",
        "                   strides=(2,2),\n",
        "                   name='max_pooling2d_5'))\n",
        "    # model.add(Flatten(name='flatten'))\n",
        "\n",
        "    # model.add(Dense(4096, activation='relu', name='fc_1'))\n",
        "    # model.add(Dropout(0.5, name='dropout_1'))\n",
        "\n",
        "    # model.add(Dense(4096, activation='relu', name='fc_2'))\n",
        "    # model.add(Dropout(0.5, name='dropout_4'))\n",
        "\n",
        "    # model.add(Dense(1000, activation='softmax', name='output'))\n",
        "    # model.add(Conv2D(filters=512,\n",
        "    #           kernel_size=(3, 3),\n",
        "    #           padding='same',\n",
        "    #           activation='relu',\n",
        "    #           input_shape=(224,224,3),\n",
        "    #           name='conv5_1'))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_img)"
      ],
      "metadata": {
        "id": "-1jEFputcVtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-Yckjty-q0k"
      },
      "outputs": [],
      "source": [
        "input_img = Input((512, 512, 3))\n",
        "model_unet = train(input_img )\n",
        "\n",
        "model_unet.compile(optimizer='adam', loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "model_unet.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGLBAnxn-qye"
      },
      "outputs": [],
      "source": [
        "checkPoint_path = \"model_checkpoints/model_unet/\"\n",
        "filepath= checkPoint_path+\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "log_dir = \"C:\\\\logs\\\\model_unet\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=3)\n",
        "\n",
        "callbacks_list = [checkpoint,tensorboard_callback]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4e41tUFpBWt"
      },
      "outputs": [],
      "source": [
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ans = tf.keras.backend.is_keras_tensor(\n",
        "    input_img\n",
        ")"
      ],
      "metadata": {
        "id": "1OhRulyHc1xK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.image_data_format()"
      ],
      "metadata": {
        "id": "A-Ld2NhDc-MJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_gen(train_data)"
      ],
      "metadata": {
        "id": "V2l9GaYARrx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fl_txkROSUEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "max_epochs = 10\n",
        "input_size = 512"
      ],
      "metadata": {
        "id": "SS5BkXxHduiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2wWznXKjSUHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DWWucdVcSUKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ntQBZZBaSUNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SujWPx4TSUVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M9JXyN59SUX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDMObH1D-zUQ"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "max_epochs = 10\n",
        "input_size = 512\n",
        "\n",
        "history = model_unet.fit(x = data_gen(train_data),\n",
        "                    steps_per_epoch=16,\n",
        "                    epochs=max_epochs,\n",
        "                    validation_data=data_gen(val_data),\n",
        "                    validation_steps=16,\n",
        "                    callbacks=callbacks_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjkhNExWAPnS"
      },
      "outputs": [],
      "source": [
        "model_unet.save('trained_models/model_unet.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9iL66XTAStZ"
      },
      "outputs": [],
      "source": [
        "test_loss,test_accuracy = model_unet.evaluate_generator(data_gen(test_data),steps=16,verbose=1)\n",
        "val_loss,val_accuracy = model_unet.evaluate_generator(data_gen(val_data),steps=16,verbose=1)\n",
        "train_loss,train_accuracy = model_unet.evaluate_generator(data_gen(train_data),steps=16,verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5059SD6ASq0"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy on TRAIN Data = {} \\t Log-loss in TRAIN Data = {} \".format(train_accuracy,train_loss))\n",
        "print(\"Accuracy on VALIDATION Data = {} \\t Log-loss in VALIDATION Data = {} \".format(val_accuracy,val_loss))\n",
        "print(\"Accuracy on TEST Data = {} \\t Log-loss in TEST Data = {} \".format(test_accuracy,test_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQlx-84y-2H_"
      },
      "outputs": [],
      "source": [
        "def print_results(model_path,split_data_df,show_images):\n",
        "    \"\"\"This function prints the input image,its ground truth mask along with predicted mask\n",
        "        model_path : Takes the path of trianed model\n",
        "        split_data_df : Takes the pd.DataFrame object that should contain image path and mask path in X and Y named columns\n",
        "        show_images : number of random images that should sampled from \"split_data_df\"\n",
        "    \"\"\"\n",
        "    samples = split_data_df.sample(n=show_images)\n",
        "    model = load_model(model_path)\n",
        "    input_img = []\n",
        "    GT_mask = []\n",
        "    Predicted_mask = []\n",
        "    for index,row in samples.iterrows():\n",
        "        image = load_img(row['X'])\n",
        "        image_arr = img_to_array(image)\n",
        "        image_arr=np.array(image_arr).reshape(-1, 512, 512, 3)/255\n",
        "        mask = imread(row['y'])\n",
        "        output = model.predict(image_arr).reshape(512, 512)\n",
        "        input_img.append(image)\n",
        "        GT_mask.append(mask)\n",
        "        Predicted_mask.append(output)\n",
        "\n",
        "    for i in range(show_images):\n",
        "        fig, ax = plt.subplots(1,3,figsize=(15, 10))\n",
        "        ax[0].imshow(input_img[i])\n",
        "        ax[0].set_title(\"Input Image\")\n",
        "        ax[1].imshow(Predicted_mask[i])\n",
        "        ax[1].set_title(\"Predicted Mask\")\n",
        "        ax[2].imshow(GT_mask[i])\n",
        "        ax[2].set_title(\"Groud Truth Mask\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTBtReKeAHgw"
      },
      "outputs": [],
      "source": [
        "# print_results(model_path='trained_models/model_unet.h5',\n",
        "#               split_data_df =test_data,show_images=10)\n",
        "print_results(model_path='trained_models/model_unet.h5',\n",
        "              split_data_df =test_data[test_data['y']!='default.mask.png'],show_images=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agWGRpiNw4Di"
      },
      "outputs": [],
      "source": [
        "test_data.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhOSRsZQAKhC"
      },
      "outputs": [],
      "source": [
        "def data_gen_fk(data):\n",
        "    data_reduced = data[data['y']!='default.mask.png']\n",
        "    while True:\n",
        "        for start in range(0, data_reduced.shape[0], batch_size):\n",
        "            x_batch = []\n",
        "            y_batch = []\n",
        "            end = min(start + batch_size, data_reduced.shape[0])\n",
        "            x_data_batch = data_reduced.iloc[start:end]\n",
        "\n",
        "            for index,row in x_data_batch.iterrows():\n",
        "                image = load_img(row['X'])\n",
        "                image = img_to_array(image)\n",
        "                mask = imread(row['y'])\n",
        "                mask= img_to_array(mask,dtype=np.uint8)\n",
        "                x_batch.append(image)\n",
        "                y_batch.append(mask)\n",
        "\n",
        "            x_batch = np.array(x_batch).reshape(-1, 512, 512, 3)/255\n",
        "            y_batch = np.array(y_batch)/255\n",
        "\n",
        "            yield x_batch, y_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVsbOvSKAu_w"
      },
      "outputs": [],
      "source": [
        "checkPoint_path = \"model_checkpoints/model_unet_fk/\"\n",
        "filepath= checkPoint_path+\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "log_dir = \"C:\\\\logs\\\\model_unet_fk\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=3)\n",
        "\n",
        "callbacks_list = [checkpoint,tensorboard_callback]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HL9WcgvlAxHa"
      },
      "outputs": [],
      "source": [
        "input_img = Input((512, 512, 3))\n",
        "model_unet_2 = get_unet(input_img, n_filters=16, dropout=0.05, batchnorm=True)\n",
        "\n",
        "model_unet_2.compile(optimizer='adam', loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "#model_unet_2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTuG4GuSAzIw"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "max_epochs = 10\n",
        "input_size = 512\n",
        "\n",
        "history = model_unet_2.fit_generator(generator = data_gen_fk(train_data),\n",
        "                    steps_per_epoch=16,\n",
        "                    epochs=max_epochs,\n",
        "                    validation_data=data_gen_fk(val_data),\n",
        "                    callbacks=callbacks_list,\n",
        "                    validation_steps=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O23ch0EZA1fe"
      },
      "outputs": [],
      "source": [
        "model_unet_2.save('trained_models/model_unet_2.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01ManDv9Cpzv"
      },
      "outputs": [],
      "source": [
        "test_loss_2,test_accuracy_2 = model_unet_2.evaluate_generator(data_gen_fk(test_data),steps=16,verbose=1)\n",
        "val_loss_2,val_accuracy_2 = model_unet_2.evaluate_generator(data_gen_fk(val_data),steps=16,verbose=1)\n",
        "train_loss_2,train_accuracy_2 = model_unet_2.evaluate_generator(data_gen_fk(train_data),steps=16,verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUqp4DwdCt10"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy on TRAIN Data = {} \\t Log-loss in TRAIN Data = {} \".format(train_accuracy_2,train_loss_2))\n",
        "print(\"Accuracy on VALIDATION Data = {} \\t Log-loss in VALIDATION Data = {} \".format(val_accuracy_2,val_loss_2))\n",
        "print(\"Accuracy on TEST Data = {} \\t Log-loss in TEST Data = {} \".format(test_accuracy_2,test_loss_2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDo2spYHDfA3"
      },
      "outputs": [],
      "source": [
        "print_results(model_path='trained_models/model_unet.h5',\n",
        "              split_data_df =test_data[test_data['y']!='default.mask.png'],show_images=25)\n",
        "\n",
        "print_results(model_path='trained_models/model_unet.h5',\n",
        "              split_data_df =test_data,show_images=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gFAAqL27d1Xi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def analyze_traffic(url):\n",
        "  \"\"\"\n",
        "  Analyzes website traffic for phishing indicators.\n",
        "\n",
        "  Args:\n",
        "    url: The website URL to analyze.\n",
        "\n",
        "  Returns:\n",
        "    Dictionary containing:\n",
        "      - total_traffic: Estimated total monthly traffic.\n",
        "      - traffic_sources: Dictionary of traffic sources and their percentages.\n",
        "      - phishing_indicators: List of potential phishing indicators.\n",
        "  \"\"\"\n",
        "\n",
        "  # Fetch website content using requests\n",
        "  response = requests.get(url)\n",
        "  content = response.content\n",
        "\n",
        "  # Extract relevant data using BeautifulSoup\n",
        "  soup = BeautifulSoup(content, \"html.parser\")\n",
        "\n",
        "  # Initialize data\n",
        "  traffic_data = {}\n",
        "  traffic_sources = {}\n",
        "  phishing_indicators = []\n",
        "\n",
        "  # Analyze traffic based on available data (example)\n",
        "  try:\n",
        "    # Estimate total traffic using external services (optional)\n",
        "    # ...\n",
        "\n",
        "    # Look for suspicious traffic sources\n",
        "    for link in soup.find_all(\"a\"):\n",
        "      href = link.get(\"href\")\n",
        "      if href and not href.startswith(url):\n",
        "        source_domain = urlparse(href).netloc\n",
        "        if source_domain not in traffic_sources:\n",
        "          traffic_sources[source_domain] = 0\n",
        "        traffic_sources[source_domain] += 1\n",
        "\n",
        "    # Check for common phishing indicators\n",
        "    if any(word in soup.text for word in [\"free\", \"money\", \"win\", \"prize\", \"urgent\"]):\n",
        "      phishing_indicators.append(\"Suspicious keywords\")\n",
        "\n",
        "    # ... (add more indicators)\n",
        "\n",
        "    traffic_data = {\n",
        "      \"total_traffic\": None,  # replace with actual value\n",
        "      \"traffic_sources\": traffic_sources,\n",
        "      \"phishing_indicators\": phishing_indicators,\n",
        "    }\n",
        "  except Exception as e:\n",
        "    print(f\"Error analyzing traffic for {url}: {e}\")\n",
        "\n",
        "  return traffic_data\n",
        "\n",
        "# Example usage\n",
        "url = \"https://www.example.com\"\n",
        "traffic_data = analyze_traffic(url)\n",
        "\n",
        "print(f\"Total traffic: {traffic_data['total_traffic']}\")\n",
        "print(f\"Traffic sources: {traffic_data['traffic_sources']}\")\n",
        "print(f\"Phishing indicators: {traffic_data['phishing_indicators']}\")\n"
      ],
      "metadata": {
        "id": "Nf_Z2OW4d1U8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_mZCnWfDhV_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}